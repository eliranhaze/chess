tourney.py --num_games 20 --rating 1600 --iterative --iter_cutoff 0.8 --book
results:
against 1650: 5-2 [0 draw]
against 1550: 11-2 [0 draw]
overall score: 16/20
performance rating: 1827

tourney.py --num_games 20 --rating 1600 --iterative --iter_cutoff 0.8
results:
against 1650: 9-3 [0 draw]
against 1550: 6-2 [0 draw]
overall score: 15/20
performance rating: 1803

-- after inf fix and time limit (in prev results sf had 0.1s limit while we had much higher) --

pypy3 tourney.py --num_games 25 --rating 1600 --iterative  --move_time 2 --book
results:
against 1550: 6-1 [0 draw]
against 1600: 6-2 [0 draw]
against 1650: 7-3 [0 draw]
overall score: 19/25
performance rating: 1808

pypy3 tourney.py --num_games 25 --rating 1600 --iterative  --move_time 2
results:
against 1650: 2-6 [0 draw]
against 1600: 6-6 [0 draw]
against 1550: 3-2 [0 draw]
overall score: 11/25
performance rating: 1563

# hmm... seems suspociously low? is book that good?

pypy3 tourney.py --num_games 100 --rating 1850 --iterative  --move_time 2 --book
run stopped
results:
against 1800: 2-6 [0 draw]
against 1900: 1-14 [0 draw]
against 1850: 0-8 [0 draw]
overall score: 3/31
performance rating (used site manually): 1490 (wut??)

=== results from google colab - with stockfish 13 (previous results use 12) ===

tourney.py --num_games 30 --rating 1600 --iterative --move_time 1.5 --book
results:
against 1600: 5-9 [0 draw]
against 1650: 3-7 [0 draw]
against 1550: 3-3 [0 draw]
overall score: 11/30
performance rating: 1509

tourney.py --num_games 30 --rating 1600 --iterative --move_time 1.5
results:
against 1600: 4-5 [0 draw]
against 1550: 4-5 [0 draw]
against 1650: 6-6 [0 draw]
overall score: 14/30
performance rating: 1582

--
June 28, Google Colab
tourney.py --num_games 50 --rating 1600 --iterative --move_time 2 --sf_path /content/chess/stockfish13 --book
results:
against 1550: 8-7 [0 draw]
against 1650: 9-5 [0 draw]
against 1600: 5-6 [0 draw]
overall score: 22/40
performance rating: 1634

tourney.py --num_games 50 --rating 1600 --iterative --move_time 2 --sf_path /content/chess/stockfish13
results:
against 1650: 8-10 [0 draw]
against 1600: 9-10 [0 draw]
against 1550: 6-7 [0 draw]
overall score: 23/50
performance rating: 1577

NOTE: just found a bug that draws were reported as losses - shouldn't have affected results that much, but still.

--
June 29-30, Google Colab
engine with king_val vs engine without
50 games: +18 =8 -24
75 games: +24 =21 -30
75 games: +20 =16 -39
overall 200 games: +62 =45 -93
elo diff: -54, according to https://www.3dkingdoms.com/chess/elo.htm

--
June 30
-- testing king_val
tourney.py --num_games 50 --rating 1500 --iterative --move_time .4 --sf_path /content/chess/stockfish13 --book
engine average move depth = 3.9
results:
against 1450: 12-4 [0 draw]
against 1550: 10-9 [0 draw]
against 1500: 6-9 [0 draw]
overall score: 28/50
performance rating: 1546
~31min

-- without king_val
tourney.py --num_games 50 --rating 1500 --iterative --move_time .4 --sf_path /content/chess/stockfish13 --book
results:
against 1500: 11-8 [1 draw]
against 1450: 6-9 [0 draw]
against 1550: 5-10 [0 draw]
overall score: 22/50
performance rating: 1471
(weird... no? probably too few games to be significant!)

-- king_val vs new king_safety (both no book)
20 games: +18 =2 -0

-- both book
75 games: +74 =0 -1
avg move depths: e1 3.6, e2 3.0

-- both book, -50,50 eval range
50 games: +46 =2 -2
avg move depths: e1 4.0, e2 3.5

-- -5,5 range: more even, still losing
25 games: +13 =4 -8
avg move depths: e1 4.2, e2 3.7

-- after top>=100 fix, -50,50 range
20 games: +19 =0 -1

idk... something going very wrong with the king safety evaluation... maybe the features aren't right, the engine is trying to optimize the wrong things, etc..
- should probably focus on more efficient search for now and continue with the simple evaluation

=======
--
June 30
-- testing qs vs check-extended qs
50 games (0.25 tpm): +10 =14 -26
avg move depths: e1 4.3, e2 4.2
-
50 games (0.25 tpm): +11 =13 -26
avg move depths: e1 4.3, e2 4.2
avg move times: e1 0.40, e2 0.38 (so not searching more as i had worried)
-
100 games (0.25): +15 =24 -61
avg move depths: e1 4.1, e2 4.0
avg move times: e1 0.38, e2 0.39
------------------------
overall: +36 =51 -113 -> +141 elo for check-extended qs version
------------------------

##################################################################################################################
# NOTE: can calculate significance with: https://www.surveymonkey.com/mp/ab-testing-significance-calculator/     #
#	just use 50% for the A test as the null hypothesis                                                       #
# NOTE: elo diff can be calculated with: https://www.3dkingdoms.com/chess/elo.htm				 #
##################################################################################################################

-- testing normal qs vs stockfish 1500
100 games [0.25]: +53 =0 -47
avg move depths: 3.7
avg move times: 0.34
--> +21 elo

-- testing check-extended qs vs stockfish 1500
100 games [0.25]: +55 =2 -43
avg move depths: 3.8
avg move times: 0.35
--> +36 elo

VERDICT: not decisive --- needs at least 300 more games each. Also maybe fix/test the 2->200 bug in QS first.

--
July 1

-- normal qs vs stockfish 1500 (again)
100 games [0.2]: +39 =4 -57
avg move depths: 3.6
avg move times: 0.29

-- check-qs vs stockfish 1500
100 games [0.2]: +45 =0 -55
avg move depths: 3.4
avg move times: 0.29

VERDICT: I conclude that check-qs is the better version! -- will commit that one.

-- delta pruning margin 2 vs margin 200 (bug fix):
265 games: something like +170 =15 -80 (lost exact results)
 - pretty weird... bug fix made it worse - maybe  the reason is that 200 is too large a margin, since with my evaluation you can't really gain a 200 positional score. maybe a smaller margin larger than 2 would work, maybe 50 or so.

-- margin 2 vs 50:
+136 =18 -36

-- margin 2 vs 20:
+35 =6 -59
avg move depths: e1 3.8, e2 3.8
avg move times: e1 0.33, e2 0.31

-- margin 2 vs 40:
+57 =8 -35
avg move depths: e1 4.0, e2 4.0
avg move times: e1 0.29, e2 0.31

i don't quite get this... but ok

-- 
July 2

-- mvv qs sort vs original qs sort
100 games [0.2]:
+67 =8 -25
avg move depths: e1 4.59, e2 4.14
avg move times: e1 0.32, e2 0.32
--> +235 elo

--
July 3
-- mvv * 16 vs mvv
100 games [0.2]:
+43 =11 -46
avg move depths: e1 4.45, e2 4.44
avg move times: e1 0.30, e2 0.28

200 games [0.2]:
+107 =11 -82
avg move depths: e1 4.58, e2 4.52
avg move times: e1 0.29, e2 0.30
--- looks better, committing change

-- mvv sort for captures in main search vs eval sort
200 games [0.2]:
+113 =32 -55
avg move depths: e1 4.61, e2 4.60
avg move times: e1 0.28, e2 0.29
(0.99 significant)
--> +104 elo

-- mvv sort for captures in main search vs stockfish 1500
200 games [0.2]: +145 =2 -53
avg move depths: 4.40
avg move times: 0.27
--> +173 elo

-- eval sort vs stockfish 1500
200 games [0.2]: +143 =8 -49
avg move depths: 4.40
avg move times: 0.28
--> +177 elo

--- strangely about the same, but note that avg move time is higher, which means that new version
    can search faster. COMMITING
