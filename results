tourney.py --num_games 20 --rating 1600 --iterative --iter_cutoff 0.8 --book
results:
against 1650: 5-2 [0 draw]
against 1550: 11-2 [0 draw]
overall score: 16/20
performance rating: 1827

tourney.py --num_games 20 --rating 1600 --iterative --iter_cutoff 0.8
results:
against 1650: 9-3 [0 draw]
against 1550: 6-2 [0 draw]
overall score: 15/20
performance rating: 1803

-- after inf fix and time limit (in prev results sf had 0.1s limit while we had much higher) --

pypy3 tourney.py --num_games 25 --rating 1600 --iterative  --move_time 2 --book
results:
against 1550: 6-1 [0 draw]
against 1600: 6-2 [0 draw]
against 1650: 7-3 [0 draw]
overall score: 19/25
performance rating: 1808

pypy3 tourney.py --num_games 25 --rating 1600 --iterative  --move_time 2
results:
against 1650: 2-6 [0 draw]
against 1600: 6-6 [0 draw]
against 1550: 3-2 [0 draw]
overall score: 11/25
performance rating: 1563

# hmm... seems suspociously low? is book that good?

pypy3 tourney.py --num_games 100 --rating 1850 --iterative  --move_time 2 --book
run stopped
results:
against 1800: 2-6 [0 draw]
against 1900: 1-14 [0 draw]
against 1850: 0-8 [0 draw]
overall score: 3/31
performance rating (used site manually): 1490 (wut??)

=== results from google colab - with stockfish 13 (previous results use 12) ===

tourney.py --num_games 30 --rating 1600 --iterative --move_time 1.5 --book
results:
against 1600: 5-9 [0 draw]
against 1650: 3-7 [0 draw]
against 1550: 3-3 [0 draw]
overall score: 11/30
performance rating: 1509

tourney.py --num_games 30 --rating 1600 --iterative --move_time 1.5
results:
against 1600: 4-5 [0 draw]
against 1550: 4-5 [0 draw]
against 1650: 6-6 [0 draw]
overall score: 14/30
performance rating: 1582

--
June 28, Google Colab
tourney.py --num_games 50 --rating 1600 --iterative --move_time 2 --sf_path /content/chess/stockfish13 --book
results:
against 1550: 8-7 [0 draw]
against 1650: 9-5 [0 draw]
against 1600: 5-6 [0 draw]
overall score: 22/40
performance rating: 1634

tourney.py --num_games 50 --rating 1600 --iterative --move_time 2 --sf_path /content/chess/stockfish13
results:
against 1650: 8-10 [0 draw]
against 1600: 9-10 [0 draw]
against 1550: 6-7 [0 draw]
overall score: 23/50
performance rating: 1577

NOTE: just found a bug that draws were reported as losses - shouldn't have affected results that much, but still.

--
June 29-30, Google Colab
engine with king_val vs engine without
50 games: +18 =8 -24
75 games: +24 =21 -30
75 games: +20 =16 -39
overall 200 games: +62 =45 -93
elo diff: -54, according to https://www.3dkingdoms.com/chess/elo.htm

--
June 30
-- testing king_val
tourney.py --num_games 50 --rating 1500 --iterative --move_time .4 --sf_path /content/chess/stockfish13 --book
engine average move depth = 3.9
results:
against 1450: 12-4 [0 draw]
against 1550: 10-9 [0 draw]
against 1500: 6-9 [0 draw]
overall score: 28/50
performance rating: 1546
~31min

-- without king_val
tourney.py --num_games 50 --rating 1500 --iterative --move_time .4 --sf_path /content/chess/stockfish13 --book
results:
against 1500: 11-8 [1 draw]
against 1450: 6-9 [0 draw]
against 1550: 5-10 [0 draw]
overall score: 22/50
performance rating: 1471
(weird... no? probably too few games to be significant!)

-- king_val vs new king_safety (both no book)
20 games: +18 =2 -0

-- both book
75 games: +74 =0 -1
avg move depths: e1 3.6, e2 3.0

-- both book, -50,50 eval range
50 games: +46 =2 -2
avg move depths: e1 4.0, e2 3.5

-- -5,5 range: more even, still losing
25 games: +13 =4 -8
avg move depths: e1 4.2, e2 3.7

-- after top>=100 fix, -50,50 range
20 games: +19 =0 -1

idk... something going very wrong with the king safety evaluation... maybe the features aren't right, the engine is trying to optimize the wrong things, etc..
- should probably focus on more efficient search for now and continue with the simple evaluation

=======
--
June 30
-- testing qs vs check-extended qs
50 games (0.25 tpm): +10 =14 -26
avg move depths: e1 4.3, e2 4.2
-
50 games (0.25 tpm): +11 =13 -26
avg move depths: e1 4.3, e2 4.2
avg move times: e1 0.40, e2 0.38 (so not searching more as i had worried)
-
100 games (0.25): +15 =24 -61
avg move depths: e1 4.1, e2 4.0
avg move times: e1 0.38, e2 0.39
------------------------
overall: +36 =51 -113 -> +141 elo for check-extended qs version
------------------------

##################################################################################################################
# NOTE: can calculate significance with: https://www.surveymonkey.com/mp/ab-testing-significance-calculator/     #
#	just use 50% for the A test as the null hypothesis                                                       #
# NOTE: elo diff can be calculated with: https://www.3dkingdoms.com/chess/elo.htm				 #
##################################################################################################################

-- testing normal qs vs stockfish 1500
100 games [0.25]: +53 =0 -47
avg move depths: 3.7
avg move times: 0.34
--> +21 elo

-- testing check-extended qs vs stockfish 1500
100 games [0.25]: +55 =2 -43
avg move depths: 3.8
avg move times: 0.35
--> +36 elo

VERDICT: not decisive --- needs at least 300 more games each. Also maybe fix/test the 2->200 bug in QS first.

--
July 1

-- normal qs vs stockfish 1500 (again)
100 games [0.2]: +39 =4 -57
avg move depths: 3.6
avg move times: 0.29

-- check-qs vs stockfish 1500
100 games [0.2]: +45 =0 -55
avg move depths: 3.4
avg move times: 0.29

VERDICT: I conclude that check-qs is the better version! -- will commit that one.

-- delta pruning margin 2 vs margin 200 (bug fix):
265 games: something like +170 =15 -80 (lost exact results)
 - pretty weird... bug fix made it worse - maybe  the reason is that 200 is too large a margin, since with my evaluation you can't really gain a 200 positional score. maybe a smaller margin larger than 2 would work, maybe 50 or so.

-- margin 2 vs 50:
+136 =18 -36

-- margin 2 vs 20:
+35 =6 -59
avg move depths: e1 3.8, e2 3.8
avg move times: e1 0.33, e2 0.31

-- margin 2 vs 40:
+57 =8 -35
avg move depths: e1 4.0, e2 4.0
avg move times: e1 0.29, e2 0.31

i don't quite get this... but ok

-- 
July 2

-- mvv qs sort vs original qs sort
100 games [0.2]:
+67 =8 -25
avg move depths: e1 4.59, e2 4.14
avg move times: e1 0.32, e2 0.32
--> +235 elo

--
July 3
-- mvv * 16 vs mvv
100 games [0.2]:
+43 =11 -46
avg move depths: e1 4.45, e2 4.44
avg move times: e1 0.30, e2 0.28

200 games [0.2]:
+107 =11 -82
avg move depths: e1 4.58, e2 4.52
avg move times: e1 0.29, e2 0.30
--- looks better, committing change

-- mvv sort for captures in main search vs eval sort
200 games [0.2]:
+113 =32 -55
avg move depths: e1 4.61, e2 4.60
avg move times: e1 0.28, e2 0.29
(0.99 significant)
--> +104 elo

-- mvv sort for captures in main search vs stockfish 1500
200 games [0.2]: +145 =2 -53
avg move depths: 4.40
avg move times: 0.27
--> +173 elo

-- eval sort vs stockfish 1500
200 games [0.2]: +143 =8 -49
avg move depths: 4.40
avg move times: 0.28
--> +177 elo

--- strangely about the same, but note that avg move time is higher, which means that new version
    can search faster. COMMITING

--
July 5
-- stable vs new game over condition
+33 =12 -55
avg move depths: e1 4.50, e2 4.63
avg move times: e1 0.30, e2 0.30

-- stable vs stockfish 1500
+67 =5 -28
avg move depths: 4.29
avg move times: 0.27

-- new game over vs stockfish 1500
+72 =2 -26
avg move depths: 4.42
avg move times: 0.28

-- stable vs new game over, again
+33 =10 -57

NOTE: realize implementation of new game over wasn't sound - not sure why it was winning

-- stable vs fixed new game over
+56 =6 -57
avg move depths: e1 4.35, e2 4.45
avg move times: e1 0.29, e2 0.30
--- worse than the version with the bug!! what's going on??

######
NOTE: it looks that the 'incorrect' version (engine3) is able to find mates even with this bug - 
it may be that those mates are found in main search anyway and not in quiesce, even though there are some undetected mates in quiesce - those are either found anyway in main search, are irrelevant, or to rare to have an effect...
NOTE 2: it may also be possible that i get skewerd scores in self play because of resignations: it's possible that because engine3 doesn't detect some mates it doesn't resign when it should, and when it does have mate the other engine resigns and detects it for him... so should also test with resignation off.
######

engine vs stockfish 1550 [0.2]
+143 =9 -98
avg move depths: 4.15
avg move times: 0.25
-> +63 elo
(note: ~95 minutes for 250 games at 0.2 tpm against stockfish)

engine3 vs stockfish 1550 [0.2]
+130 =9 -111
avg move depths: 4.28
avg move times: 0.25
-> +26 elo

engine3_1 vs stockfish 1550 [0.2]
+165 =3 -82
avg move depths: 4.18
avg move times: 0.25
-> +120 elo
(also significant vs both above) -- so change DOES work! - commit!


==========================================
320 vs 150 f prune:

Rank Name      Elo    +    - games score oppo. draws 
   1 engine3    20   30   30   100   56%   -20   17% 
   2 engine    -20   30   30   100   45%    20   17% 

Rank Name                  Elo    +    - games score oppo. draws 
   1 Cheese 2.2 [1000]    1992   59   51   150   88%  1646    8% 
   2 engine               1677   38   37   225   51%  1677    6% 
   3 engine3              1614   38   38   225   44%  1677    5% 
   4 Stockfish 13 [1550]  1550   42   43   150   39%  1646    4% 
   5 Arasan 22.3 [1300]   1490   43   45   150   31%  1646    5% 

kinda weird... running again

---
320 v 120 f prune:

Rank Name      Elo    +    - games score oppo. draws 
   1 engine3    32   25   24   150   59%   -32   21% 
   2 engine    -32   24   25   150   41%    32   21% 

Rank Name                  Elo    +    - games score oppo. draws 
   1 engine3              1644   29   28   300   60%  1562    4% 
   2 engine               1584   28   27   300   53%  1562    7% 
   3 Arasan 22.3 [1300]   1574   27   27   300   45%  1614    9% 
   4 Stockfish 13 [1550]  1550   28   29   300   43%  1614    2% 

- looks good - committing


===================================
NOTE: Just found out (July 8) that opening book was not used at all after the first game.... and most selfplay games had the same
opening moves (with that weird ass 2.. Qf6), sometimes up to move 15... Now fixed this, and added wdl per opening to game series.
So need to recheck some of the recent changes!!!! <- VERY IMPORTANT!!
